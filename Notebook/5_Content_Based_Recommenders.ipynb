{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5 Content Based Recommenders.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDnsofnYsTO7AU7jqzJwv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/Notebook/5_Content_Based_Recommenders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1IxRBsREbjO"
      },
      "source": [
        "# 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m783EMJiEjhG"
      },
      "source": [
        "<a name=\"top\"></a>\n",
        "## Content Based Recommenders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WasouTHJILH"
      },
      "source": [
        "### Table of Contents\n",
        "\n",
        "Note: The internal links work in Google Colab.\n",
        "\n",
        "1. **[Preface](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/MovieLens.ipynb#preface)**\n",
        "2. **[Introduction](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/MovieLens.ipynb#introduction)**\n",
        "3. **[Exploratory Data Analysis](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/Notebook/3_Exploratory_Data_Analysis.ipynb.ipynb#eda)**\n",
        "4. **[Framework](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/Notebook/4_Framework.ipynb#framework)**\n",
        "5. **[Content Based Recommenders](#content)**\n",
        "    - 5.1 - [Introduction](#introduction)\n",
        "    - 5.2 - [ContentKNNAlgorithm.py](#contentknnalgo)\n",
        "    - 5.3 - [Import Files](#import)\n",
        "    - 5.4 - [Models](#models)\n",
        "      - 5.4.1 - [Date & Genre](#date_genre)\n",
        "      - 5.4.2 - [Genre Only](#genre)\n",
        "      - 5.4.3 - [Date Only: Default](#date_default)\n",
        "      - 5.4.4 - [Date Only: Reverse](#date_reverse)\n",
        "      - 5.4.5 - [Date Sorted by Popularity](#date_popular)\n",
        "    - 5.5 - [Best Model](#best_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQY-F0vOcQb9"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th0Sq1sPeaIO"
      },
      "source": [
        "<a name=\"introduction\"></a>\n",
        "### 5.1 - Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVytJyi1FPeD"
      },
      "source": [
        "Content based models recommend stuff based on the attributes of those items themselves. For example in this dataset, this means recommending movies in the same genre and/or year, as movies we know somebody enjoys. The movielens dataset doesn't give us much to work with, but one thing it does tell us is which movie genres(s) each movie belongs to. For every movie, we're given a list of genres like science fiction, comedy, drama et cetera, that might apply to that movie. So if we know a given user likes drama movies, it's reasonable to recommend other drama movies to that user. \n",
        "\n",
        "This Notebook goes over Frank's code for his content based algorithms, followed by the different recommenders I tried. Last, I'll choose my favorite content based recommender.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9wkWFNcjaI1"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR-icWtwghny"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYvHDd1XgiiZ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYESrakSpuQI"
      },
      "source": [
        "<a name=\"contentknnalgo\"></a>\n",
        "### 5.2 - ContentKNNAlgorithm.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv16W03zu7kF"
      },
      "source": [
        "ContentKNN algorithm is a derived class from surpriselib'ss [AlgoBase](https://surprise.readthedocs.io/en/stable/algobase.html) class on **line 15**. This essentially allows us to build our own custom functions and use it within the surpriselib framework. After we calculate similarities, we find the \"K Nearest Neighbors\" (KNN) that are similar to the movies a user liked (or rated).. K is a hyperparameter which decides how many neighbors we want to use in our calculations, and by default, it's 40.  \n",
        "\n",
        "The `computeGenresimilarity` function **(line 53)** is based on a [cosine similarity metric](https://en.wikipedia.org/wiki/Cosine_similarity#Definition) between each movie. The code is essentially the function below. Movies are measured using 18 dimensions for each of the possible genres. Similar movies have a higher cosine similarity score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD0ui3zxzLDR"
      },
      "source": [
        "![cosine similarity picture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsnAsqnFzY4R"
      },
      "source": [
        "`ComputeyearSimilarity` **(line 66)** is just using an exponential decay function to give more weight to movies that were released at around the same time. \n",
        " \n",
        "**Line 46** under the `fit` function is where I can use both genre and year similarities to create the content recommender. I use both and either one in the following sections. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTBnkcY5tI2V"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 13:08:25 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "from surprise import AlgoBase\n",
        "from surprise import PredictionImpossible\n",
        "from MovieLens import MovieLens\n",
        "import math\n",
        "import numpy as np\n",
        "import heapq\n",
        "\n",
        "class ContentKNNAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, k=40, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        # Compute item similarity matrix based on content attributes\n",
        "\n",
        "        # Load up genre vectors for every movie\n",
        "        ml = MovieLens()\n",
        "        genres = ml.getGenres()\n",
        "        years = ml.getYears()\n",
        "        mes = ml.getMiseEnScene()\n",
        "        \n",
        "        print(\"Computing content-based similarity matrix...\")\n",
        "            \n",
        "        # Compute genre distance for every movie combination as a 2x2 matrix\n",
        "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
        "        \n",
        "        for thisRating in range(self.trainset.n_items):\n",
        "            if (thisRating % 100 == 0):\n",
        "                print(thisRating, \" of \", self.trainset.n_items)\n",
        "            for otherRating in range(thisRating+1, self.trainset.n_items):\n",
        "                thisMovieID = int(self.trainset.to_raw_iid(thisRating))\n",
        "                otherMovieID = int(self.trainset.to_raw_iid(otherRating))\n",
        "                genreSimilarity = self.computeGenreSimilarity(thisMovieID, otherMovieID, genres)\n",
        "                yearSimilarity = self.computeYearSimilarity(thisMovieID, otherMovieID, years)\n",
        "                #mesSimilarity = self.computeMiseEnSceneSimilarity(thisMovieID, otherMovieID, mes)\n",
        "                self.similarities[thisRating, otherRating] = genreSimilarity * yearSimilarity\n",
        "                self.similarities[otherRating, thisRating] = self.similarities[thisRating, otherRating]\n",
        "                \n",
        "        print(\"...done.\")\n",
        "                \n",
        "        return self\n",
        "    \n",
        "    def computeGenreSimilarity(self, movie1, movie2, genres):\n",
        "        genres1 = genres[movie1]\n",
        "        genres2 = genres[movie2]\n",
        "        sumxx, sumxy, sumyy = 0, 0, 0\n",
        "        for i in range(len(genres1)):\n",
        "            x = genres1[i]\n",
        "            y = genres2[i]\n",
        "            sumxx += x * x\n",
        "            sumyy += y * y\n",
        "            sumxy += x * y\n",
        "        \n",
        "        return sumxy/math.sqrt(sumxx*sumyy)\n",
        "    \n",
        "    def computeYearSimilarity(self, movie1, movie2, years):\n",
        "        diff = abs(years[movie1] - years[movie2])\n",
        "        sim = math.exp(-diff / 10.0)\n",
        "        return sim\n",
        "    \n",
        "    def computeMiseEnSceneSimilarity(self, movie1, movie2, mes):\n",
        "        mes1 = mes[movie1]\n",
        "        mes2 = mes[movie2]\n",
        "        if (mes1 and mes2):\n",
        "            shotLengthDiff = math.fabs(mes1[0] - mes2[0])\n",
        "            colorVarianceDiff = math.fabs(mes1[1] - mes2[1])\n",
        "            motionDiff = math.fabs(mes1[3] - mes2[3])\n",
        "            lightingDiff = math.fabs(mes1[5] - mes2[5])\n",
        "            numShotsDiff = math.fabs(mes1[6] - mes2[6])\n",
        "            return shotLengthDiff * colorVarianceDiff * motionDiff * lightingDiff * numShotsDiff\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "        \n",
        "        # Build up similarity scores between this item and everything the user rated\n",
        "        neighbors = []\n",
        "        for rating in self.trainset.ur[u]:\n",
        "            genreSimilarity = self.similarities[i,rating[0]]\n",
        "            neighbors.append( (genreSimilarity, rating[1]) )\n",
        "        \n",
        "        # Extract the top-K most-similar ratings\n",
        "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
        "        \n",
        "        # Compute average sim score of K neighbors weighted by user ratings\n",
        "        simTotal = weightedSum = 0\n",
        "        for (simScore, rating) in k_neighbors:\n",
        "            if (simScore > 0):\n",
        "                simTotal += simScore\n",
        "                weightedSum += simScore * rating\n",
        "            \n",
        "        if (simTotal == 0):\n",
        "            raise PredictionImpossible('No neighbors')\n",
        "\n",
        "        predictedRating = weightedSum / simTotal\n",
        "\n",
        "        return predictedRating\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQftmjC1qkNP"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrTtu-FCqkNQ"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3yEzvV4qkNQ"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t_MhylhYoDc"
      },
      "source": [
        "<a name=\"import\"></a>\n",
        "### 5.3 - Import Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9No6_FfKah0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6546506a-dd5d-4e24-b8d6-759965c08e0f"
      },
      "source": [
        "import os\n",
        "os.mkdir('/content/content')\n",
        "print('Folder created!')\n",
        "os.chdir('/content/content')\n",
        "print('Folder ready for upload!')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Folder created!\n",
            "Folder ready for upload!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6brgN2fOVur",
        "outputId": "52804c2d-6fc5-420a-9976-f9a5703ec88a"
      },
      "source": [
        "pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUOHw7PtK4oZ"
      },
      "source": [
        "print(\"Loading Framework...\")\n",
        "!python \"MovieLens.py\"\n",
        "print('1 of 5: Done')\n",
        "!python \"RecommenderMetrics.py\"\n",
        "print('2 of 5: Done')\n",
        "!python \"EvaluationData.py\"\n",
        "print('3 of 5: Done')\n",
        "!python \"EvaluatedAlgorithm.py\"\n",
        "print('4 of 5: Done')\n",
        "!python \"Evaluator.py\"\n",
        "print('5 of 5: Core Framework Loaded!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywi60lI3Znrm"
      },
      "source": [
        "print('Loading models...')\n",
        "!python \"ContentKNNAlgorithm\"\n",
        "print('Models loaded.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Alzy0z5faCzz"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTR_og0laCz0"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uMT3fzxaCz0"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA0Mssy5p594"
      },
      "source": [
        "<a name=\"models\"></a>\n",
        "### 5.4 - Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV8XmpaNp594"
      },
      "source": [
        "The Following section has the different recommender models I tried. I will pick my favorite for the end. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGls5ECzap5V"
      },
      "source": [
        "<a name=\"date_genre\"></a>\n",
        "#### 5.4.1 - Date & Genre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFeIUE3IBNKs"
      },
      "source": [
        "This model uses both the date and genre to recommend movies similar to the movies a user rated. This [folder](https://github.com/villafue/Capstone_2_MovieLens/tree/main/Python%20Scripts/ContentBased/ContentBasedGenreYear) contains the scripts I used for this model.\n",
        "\n",
        "On **line 38**, I initialized surpriselib's [`NormalPredictor()`](https://surprise.readthedocs.io/en/stable/basic_algorithms.html?highlight=NormalPredictor(#surprise.prediction_algorithms.random_pred.NormalPredictor) function, and saved it to the variable `Random`. `Random` creates a normal distribution around the mean of all the ratings. It's a useful benchmark for comparison to my models.\n",
        "\n",
        "On **line 41**, the argument `True` tells the algorithm to calculate the full set of metrics. Setting it to `False` saves time and only calculates the RMSE and MAE. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nFI6HFXWmYg",
        "outputId": "124392c1-65c1-4118-b4ad-d9571ee01d46"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 16:25:39 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from MovieLens import MovieLens\n",
        "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
        "from Evaluator import Evaluator\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(29)\n",
        "random.seed(29)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(True)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8775\n",
            "100  of  8775\n",
            "200  of  8775\n",
            "300  of  8775\n",
            "400  of  8775\n",
            "500  of  8775\n",
            "600  of  8775\n",
            "700  of  8775\n",
            "800  of  8775\n",
            "900  of  8775\n",
            "1000  of  8775\n",
            "1100  of  8775\n",
            "1200  of  8775\n",
            "1300  of  8775\n",
            "1400  of  8775\n",
            "1500  of  8775\n",
            "1600  of  8775\n",
            "1700  of  8775\n",
            "1800  of  8775\n",
            "1900  of  8775\n",
            "2000  of  8775\n",
            "2100  of  8775\n",
            "2200  of  8775\n",
            "2300  of  8775\n",
            "2400  of  8775\n",
            "2500  of  8775\n",
            "2600  of  8775\n",
            "2700  of  8775\n",
            "2800  of  8775\n",
            "2900  of  8775\n",
            "3000  of  8775\n",
            "3100  of  8775\n",
            "3200  of  8775\n",
            "3300  of  8775\n",
            "3400  of  8775\n",
            "3500  of  8775\n",
            "3600  of  8775\n",
            "3700  of  8775\n",
            "3800  of  8775\n",
            "3900  of  8775\n",
            "4000  of  8775\n",
            "4100  of  8775\n",
            "4200  of  8775\n",
            "4300  of  8775\n",
            "4400  of  8775\n",
            "4500  of  8775\n",
            "4600  of  8775\n",
            "4700  of  8775\n",
            "4800  of  8775\n",
            "4900  of  8775\n",
            "5000  of  8775\n",
            "5100  of  8775\n",
            "5200  of  8775\n",
            "5300  of  8775\n",
            "5400  of  8775\n",
            "5500  of  8775\n",
            "5600  of  8775\n",
            "5700  of  8775\n",
            "5800  of  8775\n",
            "5900  of  8775\n",
            "6000  of  8775\n",
            "6100  of  8775\n",
            "6200  of  8775\n",
            "6300  of  8775\n",
            "6400  of  8775\n",
            "6500  of  8775\n",
            "6600  of  8775\n",
            "6700  of  8775\n",
            "6800  of  8775\n",
            "6900  of  8775\n",
            "7000  of  8775\n",
            "7100  of  8775\n",
            "7200  of  8775\n",
            "7300  of  8775\n",
            "7400  of  8775\n",
            "7500  of  8775\n",
            "7600  of  8775\n",
            "7700  of  8775\n",
            "7800  of  8775\n",
            "7900  of  8775\n",
            "8000  of  8775\n",
            "8100  of  8775\n",
            "8200  of  8775\n",
            "8300  of  8775\n",
            "8400  of  8775\n",
            "8500  of  8775\n",
            "8600  of  8775\n",
            "8700  of  8775\n",
            "...done.\n",
            "Evaluating top-N with leave-one-out...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9709\n",
            "100  of  9709\n",
            "200  of  9709\n",
            "300  of  9709\n",
            "400  of  9709\n",
            "500  of  9709\n",
            "600  of  9709\n",
            "700  of  9709\n",
            "800  of  9709\n",
            "900  of  9709\n",
            "1000  of  9709\n",
            "1100  of  9709\n",
            "1200  of  9709\n",
            "1300  of  9709\n",
            "1400  of  9709\n",
            "1500  of  9709\n",
            "1600  of  9709\n",
            "1700  of  9709\n",
            "1800  of  9709\n",
            "1900  of  9709\n",
            "2000  of  9709\n",
            "2100  of  9709\n",
            "2200  of  9709\n",
            "2300  of  9709\n",
            "2400  of  9709\n",
            "2500  of  9709\n",
            "2600  of  9709\n",
            "2700  of  9709\n",
            "2800  of  9709\n",
            "2900  of  9709\n",
            "3000  of  9709\n",
            "3100  of  9709\n",
            "3200  of  9709\n",
            "3300  of  9709\n",
            "3400  of  9709\n",
            "3500  of  9709\n",
            "3600  of  9709\n",
            "3700  of  9709\n",
            "3800  of  9709\n",
            "3900  of  9709\n",
            "4000  of  9709\n",
            "4100  of  9709\n",
            "4200  of  9709\n",
            "4300  of  9709\n",
            "4400  of  9709\n",
            "4500  of  9709\n",
            "4600  of  9709\n",
            "4700  of  9709\n",
            "4800  of  9709\n",
            "4900  of  9709\n",
            "5000  of  9709\n",
            "5100  of  9709\n",
            "5200  of  9709\n",
            "5300  of  9709\n",
            "5400  of  9709\n",
            "5500  of  9709\n",
            "5600  of  9709\n",
            "5700  of  9709\n",
            "5800  of  9709\n",
            "5900  of  9709\n",
            "6000  of  9709\n",
            "6100  of  9709\n",
            "6200  of  9709\n",
            "6300  of  9709\n",
            "6400  of  9709\n",
            "6500  of  9709\n",
            "6600  of  9709\n",
            "6700  of  9709\n",
            "6800  of  9709\n",
            "6900  of  9709\n",
            "7000  of  9709\n",
            "7100  of  9709\n",
            "7200  of  9709\n",
            "7300  of  9709\n",
            "7400  of  9709\n",
            "7500  of  9709\n",
            "7600  of  9709\n",
            "7700  of  9709\n",
            "7800  of  9709\n",
            "7900  of  9709\n",
            "8000  of  9709\n",
            "8100  of  9709\n",
            "8200  of  9709\n",
            "8300  of  9709\n",
            "8400  of  9709\n",
            "8500  of  9709\n",
            "8600  of  9709\n",
            "8700  of  9709\n",
            "8800  of  9709\n",
            "8900  of  9709\n",
            "9000  of  9709\n",
            "9100  of  9709\n",
            "9200  of  9709\n",
            "9300  of  9709\n",
            "9400  of  9709\n",
            "9500  of  9709\n",
            "9600  of  9709\n",
            "9700  of  9709\n",
            "...done.\n",
            "Computing hit-rate and rank metrics...\n",
            "Computing recommendations with full data set...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Analyzing coverage, diversity, and novelty...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Evaluating top-N with leave-one-out...\n",
            "Computing hit-rate and rank metrics...\n",
            "Computing recommendations with full data set...\n",
            "Analyzing coverage, diversity, and novelty...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE        HR         cHR        ARHR       Coverage   Diversity  Novelty   \n",
            "ContentKNN 0.9055     0.6983     0.0000     0.0000     0.0000     0.9213     0.6245     4897.3913 \n",
            "Random     1.4227     1.1375     0.0180     0.0180     0.0090     1.0000     0.0535     843.9634  \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\n",
            "cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\n",
            "ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\n",
            "Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
            "Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\n",
            "           for a given user. Higher means more diverse.\n",
            "Novelty:   Average popularity rank of recommended items. Higher means more novel.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Psycho (1960) 5\n",
            "Troll 2 (1990) 5\n",
            "Candyman: Farewell to the Flesh (1995) 5\n",
            "2 Days in the Valley (1996) 5\n",
            "Sherlock - A Study in Pink (2010) 5\n",
            "Sound of Music, The (1965) 5\n",
            "South Pacific (1958) 5\n",
            "'Tis the Season for Love (2015) 5\n",
            "Fog of War: Eleven Lessons from the Life of Robert S. McNamara, The (2003) 5\n",
            "Message in a Bottle (1999) 5\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Batman (1989) 5\n",
            "Silence of the Lambs, The (1991) 5\n",
            "Mr. Smith Goes to Washington (1939) 5\n",
            "Basic Instinct (1992) 5\n",
            "Apocalypse Now (1979) 5\n",
            "Goodfellas (1990) 5\n",
            "Fantasia (1940) 5\n",
            "Sneakers (1992) 5\n",
            "Black Cauldron, The (1985) 5\n",
            "Negotiator, The (1998) 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xc0LB8KgBi_"
      },
      "source": [
        "Below is the table showing the metrics calculated by this model. The RMSE means that on average, the predicted ratings are 0.9055 stars off the actual rating. It predicts the accuracy of the true ratings better than `Random`, but that's not what's most important to me. Furthermore, the model has a much higher Novelty score than Random. This means, that on average, the model is recommending less popular movies. \n",
        "\n",
        "These numbers don't mean as much without qualitative context. Next, I'll print out the Top 10 movie recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_He7O3keoW2"
      },
      "source": [
        "```\n",
        "Algorithm  RMSE       MAE        HR         cHR        ARHR       Coverage   Diversity  Novelty   \n",
        "ContentKNN 0.9055     0.6983     0.0000     0.0000     0.0000     0.9213     0.6245     4897.3913 \n",
        "Random     1.4227     1.1375     0.0180     0.0180     0.0090     1.0000     0.0535     843.9634  \n",
        "\n",
        "Legend:\n",
        "\n",
        "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
        "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
        "HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\n",
        "cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\n",
        "ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\n",
        "Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
        "Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\n",
        "           for a given user. Higher means more diverse.\n",
        "Novelty:   Average popularity rank of recommended items. Higher means more novel.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiM4XoGMhFj5"
      },
      "source": [
        "The movies are okay, but it doesn't make me excited. If any streaming service recommended these movies to me, I probably wouldn't trust the algorithm. This is especially true considering [`User 25`](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/Notebook/3_Exploratory_Data_Analysis.ipynb) has similar movie tastes to my own, and these recommendations correspond to movies (s)he rated. \n",
        "\n",
        "In his course, Frank argues that building recommender systems are as much an art as a science. I know these recommended movies are subjective, but it does help to balance it against pure metrics. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ii-oEM3fboa"
      },
      "source": [
        "```\n",
        "Using recommender  ContentKNN\n",
        "\n",
        "We recommend:\n",
        "Psycho (1960) 5\n",
        "Troll 2 (1990) 5\n",
        "Candyman: Farewell to the Flesh (1995) 5\n",
        "2 Days in the Valley (1996) 5\n",
        "Sherlock - A Study in Pink (2010) 5\n",
        "Sound of Music, The (1965) 5\n",
        "South Pacific (1958) 5\n",
        "'Tis the Season for Love (2015) 5\n",
        "Fog of War: Eleven Lessons from the Life of Robert S. McNamara, The (2003) 5\n",
        "Message in a Bottle (1999) 5\n",
        "\n",
        "------------------------------------------\n",
        "\n",
        "Using recommender  Random\n",
        "\n",
        "We recommend:\n",
        "Batman (1989) 5\n",
        "Silence of the Lambs, The (1991) 5\n",
        "Mr. Smith Goes to Washington (1939) 5\n",
        "Basic Instinct (1992) 5\n",
        "Apocalypse Now (1979) 5\n",
        "Goodfellas (1990) 5\n",
        "Fantasia (1940) 5\n",
        "Sneakers (1992) 5\n",
        "Black Cauldron, The (1985) 5\n",
        "Negotiator, The (1998) 5\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idR322MEiVyK"
      },
      "source": [
        "Next, I'll try running this model calculating similarities on genre alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtx3GbhDkYG-"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9NGMSIhkYG_"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dFD4cH1kYG_"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5arfdKzkYHA"
      },
      "source": [
        "<a name=\"genre\"></a>\n",
        "#### 5.4.2 - Genre Only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhit1ph0fORV"
      },
      "source": [
        "This model uses only genre information without taking into account the release year of the movie. This [folder](https://github.com/villafue/Capstone_2_MovieLens/tree/main/Python%20Scripts/ContentBased/ContentBasedGenre) contains the scripts used for this model.\n",
        "\n",
        "To save time, I initialize the `Random` algorithm and on **line 41**, I set the argument to `False` so only the RMSE and MAE will print. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s-0efZTYSFE",
        "outputId": "8b3abfb5-c2d0-49d3-9757-8008e01498c8"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 16:25:39 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from MovieLens import MovieLens\n",
        "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
        "from Evaluator import Evaluator\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(29)\n",
        "random.seed(29)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "#Random = NormalPredictor()\n",
        "#evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8775\n",
            "100  of  8775\n",
            "200  of  8775\n",
            "300  of  8775\n",
            "400  of  8775\n",
            "500  of  8775\n",
            "600  of  8775\n",
            "700  of  8775\n",
            "800  of  8775\n",
            "900  of  8775\n",
            "1000  of  8775\n",
            "1100  of  8775\n",
            "1200  of  8775\n",
            "1300  of  8775\n",
            "1400  of  8775\n",
            "1500  of  8775\n",
            "1600  of  8775\n",
            "1700  of  8775\n",
            "1800  of  8775\n",
            "1900  of  8775\n",
            "2000  of  8775\n",
            "2100  of  8775\n",
            "2200  of  8775\n",
            "2300  of  8775\n",
            "2400  of  8775\n",
            "2500  of  8775\n",
            "2600  of  8775\n",
            "2700  of  8775\n",
            "2800  of  8775\n",
            "2900  of  8775\n",
            "3000  of  8775\n",
            "3100  of  8775\n",
            "3200  of  8775\n",
            "3300  of  8775\n",
            "3400  of  8775\n",
            "3500  of  8775\n",
            "3600  of  8775\n",
            "3700  of  8775\n",
            "3800  of  8775\n",
            "3900  of  8775\n",
            "4000  of  8775\n",
            "4100  of  8775\n",
            "4200  of  8775\n",
            "4300  of  8775\n",
            "4400  of  8775\n",
            "4500  of  8775\n",
            "4600  of  8775\n",
            "4700  of  8775\n",
            "4800  of  8775\n",
            "4900  of  8775\n",
            "5000  of  8775\n",
            "5100  of  8775\n",
            "5200  of  8775\n",
            "5300  of  8775\n",
            "5400  of  8775\n",
            "5500  of  8775\n",
            "5600  of  8775\n",
            "5700  of  8775\n",
            "5800  of  8775\n",
            "5900  of  8775\n",
            "6000  of  8775\n",
            "6100  of  8775\n",
            "6200  of  8775\n",
            "6300  of  8775\n",
            "6400  of  8775\n",
            "6500  of  8775\n",
            "6600  of  8775\n",
            "6700  of  8775\n",
            "6800  of  8775\n",
            "6900  of  8775\n",
            "7000  of  8775\n",
            "7100  of  8775\n",
            "7200  of  8775\n",
            "7300  of  8775\n",
            "7400  of  8775\n",
            "7500  of  8775\n",
            "7600  of  8775\n",
            "7700  of  8775\n",
            "7800  of  8775\n",
            "7900  of  8775\n",
            "8000  of  8775\n",
            "8100  of  8775\n",
            "8200  of  8775\n",
            "8300  of  8775\n",
            "8400  of  8775\n",
            "8500  of  8775\n",
            "8600  of  8775\n",
            "8700  of  8775\n",
            "...done.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "ContentKNN 0.9280     0.7168    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Shining, The (1980) 3.501556983616962\n",
            "Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922) 3.501556983616962\n",
            "Texas Chainsaw Massacre, The (1974) 3.501556983616962\n",
            "Dracula (1931) 3.501556983616962\n",
            "Inside Job (2010) 3.501556983616962\n",
            "The Jinx: The Life and Deaths of Robert Durst (2015) 3.501556983616962\n",
            "Crumb (1994) 3.501556983616962\n",
            "Maya Lin: A Strong Clear Vision (1994) 3.501556983616962\n",
            "High Plains Drifter (1973) 3.501556983616962\n",
            "Lord of Illusions (1995) 3.501556983616962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF0ONjg9mZQv"
      },
      "source": [
        "Below, the RMSE is around the same as the first model, but the recommendations are horrible. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6vlhg74mJm_"
      },
      "source": [
        "```\n",
        "Algorithm  RMSE       MAE       \n",
        "ContentKNN 0.9280     0.7168    \n",
        "\n",
        "Legend:\n",
        "\n",
        "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
        "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
        "\n",
        "-----------------------------------------\n",
        "\n",
        "Using recommender  ContentKNN\n",
        "\n",
        "We recommend:\n",
        "Shining, The (1980) 3.501556983616962\n",
        "Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922) 3.501556983616962\n",
        "Texas Chainsaw Massacre, The (1974) 3.501556983616962\n",
        "Dracula (1931) 3.501556983616962\n",
        "Inside Job (2010) 3.501556983616962\n",
        "The Jinx: The Life and Deaths of Robert Durst (2015) 3.501556983616962\n",
        "Crumb (1994) 3.501556983616962\n",
        "Maya Lin: A Strong Clear Vision (1994) 3.501556983616962\n",
        "High Plains Drifter (1973) 3.501556983616962\n",
        "Lord of Illusions (1995) 3.501556983616962\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNksBbtXowrJ"
      },
      "source": [
        "Next, I will try a model using date alone."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoHNPZpWos3C"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO_m9PTFos3F"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZPHnaZQos3F"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84jVRGqkos3G"
      },
      "source": [
        "<a name=\"date_default\"></a>\n",
        "#### 5.4.3 - Date Only: Default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfCq_UNnkSxE"
      },
      "source": [
        "There was an issue I found while running this model. On **line 76** in the [`Evaluator.py`](https://github.com/villafue/Capstone_2_MovieLens/blob/main/Python%20Scripts/ContentBased/ContentBasedGenreYear/Evaluator.py) module, the argument `reverse=True` seems to sort the dates in reverse. When I saw my results, I was shocked to see my model recommend mostly very old movies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cznCrTCPdkdY",
        "outputId": "b820d128-9333-4e39-f302-eb074b9f5772"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 16:25:39 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from MovieLens import MovieLens\n",
        "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
        "from Evaluator import Evaluator\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(29)\n",
        "random.seed(29)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "#Random = NormalPredictor()\n",
        "#evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8775\n",
            "100  of  8775\n",
            "200  of  8775\n",
            "300  of  8775\n",
            "400  of  8775\n",
            "500  of  8775\n",
            "600  of  8775\n",
            "700  of  8775\n",
            "800  of  8775\n",
            "900  of  8775\n",
            "1000  of  8775\n",
            "1100  of  8775\n",
            "1200  of  8775\n",
            "1300  of  8775\n",
            "1400  of  8775\n",
            "1500  of  8775\n",
            "1600  of  8775\n",
            "1700  of  8775\n",
            "1800  of  8775\n",
            "1900  of  8775\n",
            "2000  of  8775\n",
            "2100  of  8775\n",
            "2200  of  8775\n",
            "2300  of  8775\n",
            "2400  of  8775\n",
            "2500  of  8775\n",
            "2600  of  8775\n",
            "2700  of  8775\n",
            "2800  of  8775\n",
            "2900  of  8775\n",
            "3000  of  8775\n",
            "3100  of  8775\n",
            "3200  of  8775\n",
            "3300  of  8775\n",
            "3400  of  8775\n",
            "3500  of  8775\n",
            "3600  of  8775\n",
            "3700  of  8775\n",
            "3800  of  8775\n",
            "3900  of  8775\n",
            "4000  of  8775\n",
            "4100  of  8775\n",
            "4200  of  8775\n",
            "4300  of  8775\n",
            "4400  of  8775\n",
            "4500  of  8775\n",
            "4600  of  8775\n",
            "4700  of  8775\n",
            "4800  of  8775\n",
            "4900  of  8775\n",
            "5000  of  8775\n",
            "5100  of  8775\n",
            "5200  of  8775\n",
            "5300  of  8775\n",
            "5400  of  8775\n",
            "5500  of  8775\n",
            "5600  of  8775\n",
            "5700  of  8775\n",
            "5800  of  8775\n",
            "5900  of  8775\n",
            "6000  of  8775\n",
            "6100  of  8775\n",
            "6200  of  8775\n",
            "6300  of  8775\n",
            "6400  of  8775\n",
            "6500  of  8775\n",
            "6600  of  8775\n",
            "6700  of  8775\n",
            "6800  of  8775\n",
            "6900  of  8775\n",
            "7000  of  8775\n",
            "7100  of  8775\n",
            "7200  of  8775\n",
            "7300  of  8775\n",
            "7400  of  8775\n",
            "7500  of  8775\n",
            "7600  of  8775\n",
            "7700  of  8775\n",
            "7800  of  8775\n",
            "7900  of  8775\n",
            "8000  of  8775\n",
            "8100  of  8775\n",
            "8200  of  8775\n",
            "8300  of  8775\n",
            "8400  of  8775\n",
            "8500  of  8775\n",
            "8600  of  8775\n",
            "8700  of  8775\n",
            "...done.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "ContentKNN 0.9055     0.6983    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Shining, The (1980) 3.501556983616962\n",
            "Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922) 3.501556983616962\n",
            "Texas Chainsaw Massacre, The (1974) 3.501556983616962\n",
            "Dracula (1931) 3.501556983616962\n",
            "Inside Job (2010) 3.501556983616962\n",
            "The Jinx: The Life and Deaths of Robert Durst (2015) 3.501556983616962\n",
            "Crumb (1994) 3.501556983616962\n",
            "Maya Lin: A Strong Clear Vision (1994) 3.501556983616962\n",
            "High Plains Drifter (1973) 3.501556983616962\n",
            "Lord of Illusions (1995) 3.501556983616962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTcbDYS1qYBc"
      },
      "source": [
        "As seen below, the RMSE is a little bit better, but the results are atrocious. For the most part, my model recommended very old movies. \n",
        "\n",
        "```\n",
        "Algorithm  RMSE       MAE       \n",
        "ContentKNN 0.9055     0.6983    \n",
        "\n",
        "Legend:\n",
        "\n",
        "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
        "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
        "\n",
        "-----------------\n",
        "\n",
        "Using recommender  ContentKNN\n",
        "\n",
        "We recommend:\n",
        "Shining, The (1980) 3.501556983616962\n",
        "Nosferatu (Nosferatu, eine Symphonie des Grauens) (1922) 3.501556983616962\n",
        "Texas Chainsaw Massacre, The (1974) 3.501556983616962\n",
        "Dracula (1931) 3.501556983616962\n",
        "Inside Job (2010) 3.501556983616962\n",
        "The Jinx: The Life and Deaths of Robert Durst (2015) 3.501556983616962\n",
        "Crumb (1994) 3.501556983616962\n",
        "Maya Lin: A Strong Clear Vision (1994) 3.501556983616962\n",
        "High Plains Drifter (1973) 3.501556983616962\n",
        "Lord of Illusions (1995) 3.501556983616962\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcfGlS_Aq6ZG"
      },
      "source": [
        "Next, I will run this model again, but this time sort it in reverse. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajPC78P4qWAV"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqszyf0zqWAV"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50-zpc_wqWAW"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRk_tfOQqWAW"
      },
      "source": [
        "<a name=\"date_reverse\"></a>\n",
        "#### 5.4.4 - Date Only: Reverse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z6ZbYwu9Dur"
      },
      "source": [
        "On **line 76** in the [`Evaluator.py`](https://github.com/villafue/Capstone_2_MovieLens/blob/main/Python%20Scripts/ContentBased/ContentBasedDate/Evaluator.py) class, I changed the default argument from `True` to `reverse=False`. I did this because I thought the recommender was sorting dates in reverse. The files I used are [here](https://github.com/villafue/Capstone_2_MovieLens/tree/main/Python%20Scripts/ContentBased/ContentBasedDate) and the results are below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eUgY3V29CL2",
        "outputId": "90311488-5dd0-4f99-c30a-f55448010511"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 16:25:39 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from MovieLens import MovieLens\n",
        "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
        "from Evaluator import Evaluator\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(29)\n",
        "random.seed(29)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "#Random = NormalPredictor()\n",
        "#evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8775\n",
            "100  of  8775\n",
            "200  of  8775\n",
            "300  of  8775\n",
            "400  of  8775\n",
            "500  of  8775\n",
            "600  of  8775\n",
            "700  of  8775\n",
            "800  of  8775\n",
            "900  of  8775\n",
            "1000  of  8775\n",
            "1100  of  8775\n",
            "1200  of  8775\n",
            "1300  of  8775\n",
            "1400  of  8775\n",
            "1500  of  8775\n",
            "1600  of  8775\n",
            "1700  of  8775\n",
            "1800  of  8775\n",
            "1900  of  8775\n",
            "2000  of  8775\n",
            "2100  of  8775\n",
            "2200  of  8775\n",
            "2300  of  8775\n",
            "2400  of  8775\n",
            "2500  of  8775\n",
            "2600  of  8775\n",
            "2700  of  8775\n",
            "2800  of  8775\n",
            "2900  of  8775\n",
            "3000  of  8775\n",
            "3100  of  8775\n",
            "3200  of  8775\n",
            "3300  of  8775\n",
            "3400  of  8775\n",
            "3500  of  8775\n",
            "3600  of  8775\n",
            "3700  of  8775\n",
            "3800  of  8775\n",
            "3900  of  8775\n",
            "4000  of  8775\n",
            "4100  of  8775\n",
            "4200  of  8775\n",
            "4300  of  8775\n",
            "4400  of  8775\n",
            "4500  of  8775\n",
            "4600  of  8775\n",
            "4700  of  8775\n",
            "4800  of  8775\n",
            "4900  of  8775\n",
            "5000  of  8775\n",
            "5100  of  8775\n",
            "5200  of  8775\n",
            "5300  of  8775\n",
            "5400  of  8775\n",
            "5500  of  8775\n",
            "5600  of  8775\n",
            "5700  of  8775\n",
            "5800  of  8775\n",
            "5900  of  8775\n",
            "6000  of  8775\n",
            "6100  of  8775\n",
            "6200  of  8775\n",
            "6300  of  8775\n",
            "6400  of  8775\n",
            "6500  of  8775\n",
            "6600  of  8775\n",
            "6700  of  8775\n",
            "6800  of  8775\n",
            "6900  of  8775\n",
            "7000  of  8775\n",
            "7100  of  8775\n",
            "7200  of  8775\n",
            "7300  of  8775\n",
            "7400  of  8775\n",
            "7500  of  8775\n",
            "7600  of  8775\n",
            "7700  of  8775\n",
            "7800  of  8775\n",
            "7900  of  8775\n",
            "8000  of  8775\n",
            "8100  of  8775\n",
            "8200  of  8775\n",
            "8300  of  8775\n",
            "8400  of  8775\n",
            "8500  of  8775\n",
            "8600  of  8775\n",
            "8700  of  8775\n",
            "...done.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "ContentKNN 0.9336     0.7224    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Ant-Man and the Wasp (2018) 4.7450497998793395\n",
            "The Darkest Minds (2018) 4.7450497998793395\n",
            "Annihilation (2018) 4.7450497998793395\n",
            "Game Night (2018) 4.7450497998793395\n",
            "Tomb Raider (2018) 4.7450497998793395\n",
            "Alpha (2018) 4.7450497998793395\n",
            "Solo: A Star Wars Story (2018) 4.7450497998793395\n",
            "Fred Armisen: Standup for Drummers (2018) 4.7450497998793395\n",
            "Tom Segura: Disgraceful (2018) 4.7450497998793395\n",
            "When We First Met (2018) 4.7450497998793395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC7ZZvbaomJB"
      },
      "source": [
        "Below are the results. The RMSE is around what I've seen for the other recommenders. However, I absolutely love these results! I would be ecstatic if a streaming service recommended these movies to me. Keep in mind, that Frank wrote the algorithm so that any movie `User 25` already [rated](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/Notebook/3_Exploratory_Data_Analysis.ipynb) could not be recommended. This means that the recommendation system has to find other movies `User 25` would enjoy, and this extra challenge makes the Top 10 results that much more critical. \n",
        "\n",
        "```\n",
        "Algorithm  RMSE       MAE       \n",
        "ContentKNN 0.9336     0.7224    \n",
        "\n",
        "Legend:\n",
        "\n",
        "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
        "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
        "\n",
        "--------------------\n",
        "\n",
        "Using recommender  ContentKNN\n",
        "\n",
        "We recommend:\n",
        "Ant-Man and the Wasp (2018) 4.7450497998793395\n",
        "The Darkest Minds (2018) 4.7450497998793395\n",
        "Annihilation (2018) 4.7450497998793395\n",
        "Game Night (2018) 4.7450497998793395\n",
        "Tomb Raider (2018) 4.7450497998793395\n",
        "Alpha (2018) 4.7450497998793395\n",
        "Solo: A Star Wars Story (2018) 4.7450497998793395\n",
        "Fred Armisen: Standup for Drummers (2018) 4.7450497998793395\n",
        "Tom Segura: Disgraceful (2018) 4.7450497998793395\n",
        "When We First Met (2018) 4.7450497998793395\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO_j86gMxmN8"
      },
      "source": [
        "Next, I will do something similar to this model but also sort the movies by popularity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XucHB3ZtvfO7"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUIAz3P2vfO7"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mjiz9dAvfO7"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJXSOTqkvfO8"
      },
      "source": [
        "<a name=\"date_popular\"></a>\n",
        "#### 5.4.5 - Date Sorted by Popularity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXxItIROZELY"
      },
      "source": [
        "This one is similar but also sorts the results by popularity as well as date. This was done by adding the code `recommendations.sort(key=lambda x: x[2])` on **line 76** in the [`Evaluator.py`](https://github.com/villafue/Capstone_2_MovieLens/blob/main/Python%20Scripts/ContentBased/ContentBasedDatePopularity/Evaluator.py). I files I used are [here](https://github.com/villafue/Capstone_2_MovieLens/tree/main/Python%20Scripts/ContentBased/ContentBasedDatePopularity)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtbOIAarMPW3",
        "outputId": "59521b32-b30b-4fcd-87bb-a76985c81af7"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 16:25:39 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from MovieLens import MovieLens\n",
        "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
        "from Evaluator import Evaluator\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(29)\n",
        "random.seed(29)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "#Random = NormalPredictor()\n",
        "#evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8775\n",
            "100  of  8775\n",
            "200  of  8775\n",
            "300  of  8775\n",
            "400  of  8775\n",
            "500  of  8775\n",
            "600  of  8775\n",
            "700  of  8775\n",
            "800  of  8775\n",
            "900  of  8775\n",
            "1000  of  8775\n",
            "1100  of  8775\n",
            "1200  of  8775\n",
            "1300  of  8775\n",
            "1400  of  8775\n",
            "1500  of  8775\n",
            "1600  of  8775\n",
            "1700  of  8775\n",
            "1800  of  8775\n",
            "1900  of  8775\n",
            "2000  of  8775\n",
            "2100  of  8775\n",
            "2200  of  8775\n",
            "2300  of  8775\n",
            "2400  of  8775\n",
            "2500  of  8775\n",
            "2600  of  8775\n",
            "2700  of  8775\n",
            "2800  of  8775\n",
            "2900  of  8775\n",
            "3000  of  8775\n",
            "3100  of  8775\n",
            "3200  of  8775\n",
            "3300  of  8775\n",
            "3400  of  8775\n",
            "3500  of  8775\n",
            "3600  of  8775\n",
            "3700  of  8775\n",
            "3800  of  8775\n",
            "3900  of  8775\n",
            "4000  of  8775\n",
            "4100  of  8775\n",
            "4200  of  8775\n",
            "4300  of  8775\n",
            "4400  of  8775\n",
            "4500  of  8775\n",
            "4600  of  8775\n",
            "4700  of  8775\n",
            "4800  of  8775\n",
            "4900  of  8775\n",
            "5000  of  8775\n",
            "5100  of  8775\n",
            "5200  of  8775\n",
            "5300  of  8775\n",
            "5400  of  8775\n",
            "5500  of  8775\n",
            "5600  of  8775\n",
            "5700  of  8775\n",
            "5800  of  8775\n",
            "5900  of  8775\n",
            "6000  of  8775\n",
            "6100  of  8775\n",
            "6200  of  8775\n",
            "6300  of  8775\n",
            "6400  of  8775\n",
            "6500  of  8775\n",
            "6600  of  8775\n",
            "6700  of  8775\n",
            "6800  of  8775\n",
            "6900  of  8775\n",
            "7000  of  8775\n",
            "7100  of  8775\n",
            "7200  of  8775\n",
            "7300  of  8775\n",
            "7400  of  8775\n",
            "7500  of  8775\n",
            "7600  of  8775\n",
            "7700  of  8775\n",
            "7800  of  8775\n",
            "7900  of  8775\n",
            "8000  of  8775\n",
            "8100  of  8775\n",
            "8200  of  8775\n",
            "8300  of  8775\n",
            "8400  of  8775\n",
            "8500  of  8775\n",
            "8600  of  8775\n",
            "8700  of  8775\n",
            "...done.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "ContentKNN 0.9336     0.7224    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Solo: A Star Wars Story (2018) 4.7450497998793395\n",
            "Isle of Dogs (2018) 4.7450497998793395\n",
            "Tomb Raider (2018) 4.7450497998793395\n",
            "A Quiet Place (2018) 4.7450497998793395\n",
            "Ant-Man and the Wasp (2018) 4.7450497998793395\n",
            "Annihilation (2018) 4.7450497998793395\n",
            "Fred Armisen: Standup for Drummers (2018) 4.7450497998793395\n",
            "When We First Met (2018) 4.7450497998793395\n",
            "Mission: Impossible - Fallout (2018) 4.7450497998793395\n",
            "The Cloverfield Paradox (2018) 4.7450497998793395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmoPs_p0oUGg"
      },
      "source": [
        "As seen below, the RMSE is average to all the prior models, and I love the results as well. However, this recommender took over double the amount of time as the model above, and the results were about the same. Because of how long it took to train, I would not use this model.\n",
        "\n",
        "```\n",
        "Algorithm  RMSE       MAE       \n",
        "ContentKNN 0.9336     0.7224    \n",
        "\n",
        "Legend:\n",
        "\n",
        "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
        "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
        "\n",
        "---------------\n",
        "\n",
        "Using recommender  ContentKNN\n",
        "\n",
        "We recommend:\n",
        "Solo: A Star Wars Story (2018) 4.7450497998793395\n",
        "Isle of Dogs (2018) 4.7450497998793395\n",
        "Tomb Raider (2018) 4.7450497998793395\n",
        "A Quiet Place (2018) 4.7450497998793395\n",
        "Ant-Man and the Wasp (2018) 4.7450497998793395\n",
        "Annihilation (2018) 4.7450497998793395\n",
        "Fred Armisen: Standup for Drummers (2018) 4.7450497998793395\n",
        "When We First Met (2018) 4.7450497998793395\n",
        "Mission: Impossible - Fallout (2018) 4.7450497998793395\n",
        "The Cloverfield Paradox (2018) 4.7450497998793395\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeKLOL9gzhnk"
      },
      "source": [
        "Below is my content-based model of choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmwylGIYn05H"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szva0e7En05I"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0zSkxgpn05I"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-fg_Dp0n05I"
      },
      "source": [
        "<a name=\"best_model\"></a>\n",
        "### 5.5 - Best Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVOjP6mWpj2o"
      },
      "source": [
        "My favorite model is [Date Only: Reverse](#date_reverse). I admit I'm biased towards the most recent movies, but I will argue that these popular movies would satisfy most customers. \n",
        "\n",
        "This is the exact same model in section 5.4.4, the only difference being I'm calculating the full metrics, as well as comparing it to `Random` algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUw4pDCmpiw8",
        "outputId": "bfe6eddc-5840-46eb-bdcb-056b7985f7f6"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri May  4 16:25:39 2018\n",
        "\n",
        "@author: Frank\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from MovieLens import MovieLens\n",
        "from ContentKNNAlgorithm import ContentKNNAlgorithm\n",
        "from Evaluator import Evaluator\n",
        "from surprise import NormalPredictor\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(29)\n",
        "random.seed(29)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "contentKNN = ContentKNNAlgorithm()\n",
        "evaluator.AddAlgorithm(contentKNN, \"ContentKNN\")\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "\n",
        "evaluator.Evaluate(True)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8775\n",
            "100  of  8775\n",
            "200  of  8775\n",
            "300  of  8775\n",
            "400  of  8775\n",
            "500  of  8775\n",
            "600  of  8775\n",
            "700  of  8775\n",
            "800  of  8775\n",
            "900  of  8775\n",
            "1000  of  8775\n",
            "1100  of  8775\n",
            "1200  of  8775\n",
            "1300  of  8775\n",
            "1400  of  8775\n",
            "1500  of  8775\n",
            "1600  of  8775\n",
            "1700  of  8775\n",
            "1800  of  8775\n",
            "1900  of  8775\n",
            "2000  of  8775\n",
            "2100  of  8775\n",
            "2200  of  8775\n",
            "2300  of  8775\n",
            "2400  of  8775\n",
            "2500  of  8775\n",
            "2600  of  8775\n",
            "2700  of  8775\n",
            "2800  of  8775\n",
            "2900  of  8775\n",
            "3000  of  8775\n",
            "3100  of  8775\n",
            "3200  of  8775\n",
            "3300  of  8775\n",
            "3400  of  8775\n",
            "3500  of  8775\n",
            "3600  of  8775\n",
            "3700  of  8775\n",
            "3800  of  8775\n",
            "3900  of  8775\n",
            "4000  of  8775\n",
            "4100  of  8775\n",
            "4200  of  8775\n",
            "4300  of  8775\n",
            "4400  of  8775\n",
            "4500  of  8775\n",
            "4600  of  8775\n",
            "4700  of  8775\n",
            "4800  of  8775\n",
            "4900  of  8775\n",
            "5000  of  8775\n",
            "5100  of  8775\n",
            "5200  of  8775\n",
            "5300  of  8775\n",
            "5400  of  8775\n",
            "5500  of  8775\n",
            "5600  of  8775\n",
            "5700  of  8775\n",
            "5800  of  8775\n",
            "5900  of  8775\n",
            "6000  of  8775\n",
            "6100  of  8775\n",
            "6200  of  8775\n",
            "6300  of  8775\n",
            "6400  of  8775\n",
            "6500  of  8775\n",
            "6600  of  8775\n",
            "6700  of  8775\n",
            "6800  of  8775\n",
            "6900  of  8775\n",
            "7000  of  8775\n",
            "7100  of  8775\n",
            "7200  of  8775\n",
            "7300  of  8775\n",
            "7400  of  8775\n",
            "7500  of  8775\n",
            "7600  of  8775\n",
            "7700  of  8775\n",
            "7800  of  8775\n",
            "7900  of  8775\n",
            "8000  of  8775\n",
            "8100  of  8775\n",
            "8200  of  8775\n",
            "8300  of  8775\n",
            "8400  of  8775\n",
            "8500  of  8775\n",
            "8600  of  8775\n",
            "8700  of  8775\n",
            "...done.\n",
            "Evaluating top-N with leave-one-out...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9709\n",
            "100  of  9709\n",
            "200  of  9709\n",
            "300  of  9709\n",
            "400  of  9709\n",
            "500  of  9709\n",
            "600  of  9709\n",
            "700  of  9709\n",
            "800  of  9709\n",
            "900  of  9709\n",
            "1000  of  9709\n",
            "1100  of  9709\n",
            "1200  of  9709\n",
            "1300  of  9709\n",
            "1400  of  9709\n",
            "1500  of  9709\n",
            "1600  of  9709\n",
            "1700  of  9709\n",
            "1800  of  9709\n",
            "1900  of  9709\n",
            "2000  of  9709\n",
            "2100  of  9709\n",
            "2200  of  9709\n",
            "2300  of  9709\n",
            "2400  of  9709\n",
            "2500  of  9709\n",
            "2600  of  9709\n",
            "2700  of  9709\n",
            "2800  of  9709\n",
            "2900  of  9709\n",
            "3000  of  9709\n",
            "3100  of  9709\n",
            "3200  of  9709\n",
            "3300  of  9709\n",
            "3400  of  9709\n",
            "3500  of  9709\n",
            "3600  of  9709\n",
            "3700  of  9709\n",
            "3800  of  9709\n",
            "3900  of  9709\n",
            "4000  of  9709\n",
            "4100  of  9709\n",
            "4200  of  9709\n",
            "4300  of  9709\n",
            "4400  of  9709\n",
            "4500  of  9709\n",
            "4600  of  9709\n",
            "4700  of  9709\n",
            "4800  of  9709\n",
            "4900  of  9709\n",
            "5000  of  9709\n",
            "5100  of  9709\n",
            "5200  of  9709\n",
            "5300  of  9709\n",
            "5400  of  9709\n",
            "5500  of  9709\n",
            "5600  of  9709\n",
            "5700  of  9709\n",
            "5800  of  9709\n",
            "5900  of  9709\n",
            "6000  of  9709\n",
            "6100  of  9709\n",
            "6200  of  9709\n",
            "6300  of  9709\n",
            "6400  of  9709\n",
            "6500  of  9709\n",
            "6600  of  9709\n",
            "6700  of  9709\n",
            "6800  of  9709\n",
            "6900  of  9709\n",
            "7000  of  9709\n",
            "7100  of  9709\n",
            "7200  of  9709\n",
            "7300  of  9709\n",
            "7400  of  9709\n",
            "7500  of  9709\n",
            "7600  of  9709\n",
            "7700  of  9709\n",
            "7800  of  9709\n",
            "7900  of  9709\n",
            "8000  of  9709\n",
            "8100  of  9709\n",
            "8200  of  9709\n",
            "8300  of  9709\n",
            "8400  of  9709\n",
            "8500  of  9709\n",
            "8600  of  9709\n",
            "8700  of  9709\n",
            "8800  of  9709\n",
            "8900  of  9709\n",
            "9000  of  9709\n",
            "9100  of  9709\n",
            "9200  of  9709\n",
            "9300  of  9709\n",
            "9400  of  9709\n",
            "9500  of  9709\n",
            "9600  of  9709\n",
            "9700  of  9709\n",
            "...done.\n",
            "Computing hit-rate and rank metrics...\n",
            "Computing recommendations with full data set...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Analyzing coverage, diversity, and novelty...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Evaluating top-N with leave-one-out...\n",
            "Computing hit-rate and rank metrics...\n",
            "Computing recommendations with full data set...\n",
            "Analyzing coverage, diversity, and novelty...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE        HR         cHR        ARHR       Coverage   Diversity  Novelty   \n",
            "ContentKNN 0.9336     0.7224     0.0049     0.0049     0.0012     0.5492     0.3442     2981.5376 \n",
            "Random     1.4206     1.1336     0.0180     0.0180     0.0072     1.0000     0.0522     854.7062  \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\n",
            "cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\n",
            "ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\n",
            "Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
            "Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\n",
            "           for a given user. Higher means more diverse.\n",
            "Novelty:   Average popularity rank of recommended items. Higher means more novel.\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9724\n",
            "100  of  9724\n",
            "200  of  9724\n",
            "300  of  9724\n",
            "400  of  9724\n",
            "500  of  9724\n",
            "600  of  9724\n",
            "700  of  9724\n",
            "800  of  9724\n",
            "900  of  9724\n",
            "1000  of  9724\n",
            "1100  of  9724\n",
            "1200  of  9724\n",
            "1300  of  9724\n",
            "1400  of  9724\n",
            "1500  of  9724\n",
            "1600  of  9724\n",
            "1700  of  9724\n",
            "1800  of  9724\n",
            "1900  of  9724\n",
            "2000  of  9724\n",
            "2100  of  9724\n",
            "2200  of  9724\n",
            "2300  of  9724\n",
            "2400  of  9724\n",
            "2500  of  9724\n",
            "2600  of  9724\n",
            "2700  of  9724\n",
            "2800  of  9724\n",
            "2900  of  9724\n",
            "3000  of  9724\n",
            "3100  of  9724\n",
            "3200  of  9724\n",
            "3300  of  9724\n",
            "3400  of  9724\n",
            "3500  of  9724\n",
            "3600  of  9724\n",
            "3700  of  9724\n",
            "3800  of  9724\n",
            "3900  of  9724\n",
            "4000  of  9724\n",
            "4100  of  9724\n",
            "4200  of  9724\n",
            "4300  of  9724\n",
            "4400  of  9724\n",
            "4500  of  9724\n",
            "4600  of  9724\n",
            "4700  of  9724\n",
            "4800  of  9724\n",
            "4900  of  9724\n",
            "5000  of  9724\n",
            "5100  of  9724\n",
            "5200  of  9724\n",
            "5300  of  9724\n",
            "5400  of  9724\n",
            "5500  of  9724\n",
            "5600  of  9724\n",
            "5700  of  9724\n",
            "5800  of  9724\n",
            "5900  of  9724\n",
            "6000  of  9724\n",
            "6100  of  9724\n",
            "6200  of  9724\n",
            "6300  of  9724\n",
            "6400  of  9724\n",
            "6500  of  9724\n",
            "6600  of  9724\n",
            "6700  of  9724\n",
            "6800  of  9724\n",
            "6900  of  9724\n",
            "7000  of  9724\n",
            "7100  of  9724\n",
            "7200  of  9724\n",
            "7300  of  9724\n",
            "7400  of  9724\n",
            "7500  of  9724\n",
            "7600  of  9724\n",
            "7700  of  9724\n",
            "7800  of  9724\n",
            "7900  of  9724\n",
            "8000  of  9724\n",
            "8100  of  9724\n",
            "8200  of  9724\n",
            "8300  of  9724\n",
            "8400  of  9724\n",
            "8500  of  9724\n",
            "8600  of  9724\n",
            "8700  of  9724\n",
            "8800  of  9724\n",
            "8900  of  9724\n",
            "9000  of  9724\n",
            "9100  of  9724\n",
            "9200  of  9724\n",
            "9300  of  9724\n",
            "9400  of  9724\n",
            "9500  of  9724\n",
            "9600  of  9724\n",
            "9700  of  9724\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Ant-Man and the Wasp (2018) 4.7450497998793395\n",
            "The Darkest Minds (2018) 4.7450497998793395\n",
            "Annihilation (2018) 4.7450497998793395\n",
            "Game Night (2018) 4.7450497998793395\n",
            "Tomb Raider (2018) 4.7450497998793395\n",
            "Alpha (2018) 4.7450497998793395\n",
            "Solo: A Star Wars Story (2018) 4.7450497998793395\n",
            "Fred Armisen: Standup for Drummers (2018) 4.7450497998793395\n",
            "Tom Segura: Disgraceful (2018) 4.7450497998793395\n",
            "When We First Met (2018) 4.7450497998793395\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) 1\n",
            "Warrior (2011) 1\n",
            "Corrina, Corrina (1994) 1\n",
            "It Could Happen to You (1994) 1\n",
            "Hot Shots! Part Deux (1993) 1\n",
            "Up in the Air (2009) 1\n",
            "Life of Pi (2012) 1\n",
            "Amistad (1997) 1\n",
            "Johnny Mnemonic (1995) 1\n",
            "The Hunger Games (2012) 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8Av-WE81LC_"
      },
      "source": [
        "As seen below, the `Novelty` metric is much higher than `Random` which means, on average, the recommender is choosing less popular movies. Furthermore, the `Coverage` metric is only recommending about 55% of the available movies. Still, if I had to pick only one of the prior content-based models, this would be it due to the recommendations.\n",
        "\n",
        "```\n",
        "Algorithm  RMSE       MAE        HR         cHR        ARHR       Coverage   Diversity  Novelty   \n",
        "ContentKNN 0.9336     0.7224     0.0049     0.0049     0.0012     0.5492     0.3442     2981.5376 \n",
        "Random     1.4206     1.1336     0.0180     0.0180     0.0072     1.0000     0.0522     854.7062  \n",
        "\n",
        "Legend:\n",
        "\n",
        "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
        "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
        "HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\n",
        "cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\n",
        "ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\n",
        "Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\n",
        "Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\n",
        "           for a given user. Higher means more diverse.\n",
        "Novelty:   Average popularity rank of recommended items. Higher means more novel.\n",
        "\n",
        "-------------------\n",
        "\n",
        "Using recommender  ContentKNN\n",
        "\n",
        "We recommend:\n",
        "Ant-Man and the Wasp (2018) 4.7450497998793395\n",
        "The Darkest Minds (2018) 4.7450497998793395\n",
        "Annihilation (2018) 4.7450497998793395\n",
        "Game Night (2018) 4.7450497998793395\n",
        "Tomb Raider (2018) 4.7450497998793395\n",
        "Alpha (2018) 4.7450497998793395\n",
        "Solo: A Star Wars Story (2018) 4.7450497998793395\n",
        "Fred Armisen: Standup for Drummers (2018) 4.7450497998793395\n",
        "Tom Segura: Disgraceful (2018) 4.7450497998793395\n",
        "When We First Met (2018) 4.7450497998793395\n",
        "\n",
        "Using recommender  Random\n",
        "\n",
        "We recommend:\n",
        "Star Wars: Episode V - The Empire Strikes Back (1980) 1\n",
        "Warrior (2011) 1\n",
        "Corrina, Corrina (1994) 1\n",
        "It Could Happen to You (1994) 1\n",
        "Hot Shots! Part Deux (1993) 1\n",
        "Up in the Air (2009) 1\n",
        "Life of Pi (2012) 1\n",
        "Amistad (1997) 1\n",
        "Johnny Mnemonic (1995) 1\n",
        "The Hunger Games (2012) 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLzr1J0TfYRK"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9xvMgc66fpz"
      },
      "source": [
        "**[Next Section](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/Notebook/6_Collaborative_Based_Recommenders.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcY81gt34Qd4"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brMtBr966Kln"
      },
      "source": [
        "**[Back to Top](#top)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5UQ9O5k4Ub9"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLedvFBX5EJA"
      },
      "source": [
        "**[Back to Main](https://colab.research.google.com/github/villafue/Capstone_2_MovieLens/blob/main/MovieLens.ipynb)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WM1LLNa4OQ7"
      },
      "source": [
        "***"
      ]
    }
  ]
}